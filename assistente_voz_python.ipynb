{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrPlBjToFPWNl8IRkC7WMc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samuelcmaggi/assistente-voz-python/blob/main/assistente_voz_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1: Instalações (Rode isso primeiro)"
      ],
      "metadata": {
        "id": "19-sdLBMY2cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q\n",
        "!pip install openai gTTS\n",
        "!sudo apt-get install -y ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Oy8zORtMY89J",
        "outputId": "122f2e47-50ab-40ae-fe10-d517d35e259a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.16.0)\n",
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.12/dist-packages (2.5.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from gTTS) (2.32.4)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.12/dist-packages (from gTTS) (8.1.8)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (2.5.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2: Funções de Gravação"
      ],
      "metadata": {
        "id": "1M7snNTzZA1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importações\n",
        "import whisper\n",
        "import os\n",
        "import openai\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio, display, Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "\n",
        "# Configuração da API Key (Troque pelo seu, ou use secrets do Colab)\n",
        "# Se for usar direto, cuidado para não vazar sua chave no GitHub!\n",
        "# O ideal é usar: from google.colab import userdata; api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = 'from getpass import getpass\n",
        "minha_api_key = getpass(\"Digite sua API Key: \")'\n",
        "openai.api_key = os.environ.get('OPENAI_API_KEY')\n",
        "\n",
        "# Inicializa o cliente OpenAI\n",
        "client = openai.OpenAI()\n",
        "\n",
        "# --- Função para gravar áudio no navegador ---\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record(sec=5):\n",
        "  display(Javascript(RECORD))\n",
        "  js_result = output.eval_js('record(%s)' % (sec * 1000))\n",
        "  audio = b64decode(js_result.split(',')[1])\n",
        "  file_name = 'request_audio.wav'\n",
        "  with open(file_name, 'wb') as f:\n",
        "    f.write(audio)\n",
        "  return f'/content/{file_name}'\n",
        "\n",
        "print(\"Configuração concluída!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sMwGrWYZFmg",
        "outputId": "be10d4ce-104d-4e4c-e0f8-538658ff5dcd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuração concluída!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3: Executar o Assistente"
      ],
      "metadata": {
        "id": "XKG_KiwMZZYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- IMPORTANTE: Instale a biblioteca antes se ainda não tiver feito ---\n",
        "# !pip install openai\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "import whisper\n",
        "# Se precisar de outras importações (como gTTS, record, etc), mantenha as que você já tinha nas células anteriores\n",
        "\n",
        "# 1. Configuração do Cliente OpenAI\n",
        "# COLE SUA CHAVE DENTRO DAS ASPAS ABAIXO:\n",
        "minha_api_key = \"from getpass import getpass\n",
        "minha_api_key = getpass(\"Digite sua API Key: \")\"\n",
        "\n",
        "client = OpenAI(api_key=minha_api_key)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# O RESTANTE DO SEU CÓDIGO (JÁ INTEGRADO):\n",
        "\n",
        "# ... (Seu código de gravação de áudio deve vir antes aqui) ...\n",
        "# Vou assumir que você já gravou e tem a variável 'record_file' pronta, como na sua imagem.\n",
        "\n",
        "# Definição do idioma\n",
        "language = 'pt'\n",
        "\n",
        "# 2. Transcrever (Whisper)\n",
        "print('Transcrevendo...')\n",
        "# Carrega o modelo (pode demorar um pouquinho na primeira vez)\n",
        "model = whisper.load_model(\"small\")\n",
        "result = model.transcribe(record_file, fp16=False, language=language)\n",
        "transcription = result[\"text\"]\n",
        "print(f\"Você disse: {transcription}\")\n",
        "\n",
        "# 3. Enviar para a IA (ChatGPT)\n",
        "if transcription.strip():\n",
        "    print('Consultando a IA...')\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Você é um assistente útil.\"},\n",
        "                {\"role\": \"user\", \"content\": transcription}\n",
        "            ]\n",
        "        )\n",
        "        chatgpt_response = response.choices[0].message.content\n",
        "        print(f\"Resposta: {chatgpt_response}\")\n",
        "\n",
        "        # 4. Falar a Resposta (gTTS)\n",
        "        # (Certifique-se de ter importado gTTS e Audio lá em cima ou na célula anterior)\n",
        "        print('Gerando áudio...')\n",
        "        from gtts import gTTS\n",
        "        from IPython.display import Audio, display\n",
        "\n",
        "        gtts_object = gTTS(text=chatgpt_response, lang=language, slow=False)\n",
        "        response_audio = \"response_audio.wav\"\n",
        "        gtts_object.save(response_audio)\n",
        "        display(Audio(response_audio, autoplay=True))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao conectar com a OpenAI: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"Não consegui ouvir nada.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDiH4kmrZcbr",
        "outputId": "0a9f4798-1f33-4b6a-b539-24f8df428c5b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcrevendo...\n",
            "Você disse:  Se vocês beficam, a paz à vida per нравится\n",
            "Consultando a IA...\n",
            "Erro ao conectar com a OpenAI: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        }
      ]
    }
  ]
}